{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Libraries**"
      ],
      "metadata": {
        "id": "tA8f1GNhRn81"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0flikm4mQIEF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.svm import SVC\n",
        "from skimage.feature import local_binary_pattern, hog\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Gun ( Pre processing)**\n",
        "*Creating Features array*\n",
        "\n",
        "Run once for creating training arrays, then for Testing arrays.\n"
      ],
      "metadata": {
        "id": "2PvIOmWURsA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_lbp_features(image, radius=1, n_points=8, method='uniform'):\n",
        "    lbp = local_binary_pattern(image, n_points, radius, method=method)\n",
        "    n_bins = int(lbp.max() + 1)\n",
        "    lbp_hist, _ = np.histogram(lbp, bins=n_bins, range=(0, n_bins), density=True)\n",
        "    return lbp, lbp_hist\n",
        "\n",
        "#For testing data\n",
        "folder_path = r\"/content/drive/MyDrive/students_data/test/gun\"\n",
        "mask_folder_path = r\"/content/drive/MyDrive/students_data/test/annotations/gun\"\n",
        "\n",
        "\n",
        "#For training data\n",
        "#folder_path = r\"/content/drive/MyDrive/students_data/train/gun\"\n",
        "#mask_folder_path = r\"/content/drive/MyDrive/students_data/train/annotations/gun\"\n",
        "images = os.listdir(folder_path)\n",
        "\n",
        "features_list = []\n",
        "\n",
        "for image_name in images:\n",
        "    image_path = os.path.join(folder_path, image_name)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    image = cv2.resize(image, (512, 512))\n",
        "\n",
        "    mask_path = os.path.join(mask_folder_path, image_name)\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "     # Check if mask was loaded successfully\n",
        "    if mask is None:\n",
        "        print(f\"Error loading mask for image: {image_name}. Check if the file exists and is not corrupted.\")\n",
        "        continue  # Skip to the next image if mask loading failed\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    mask = cv2.resize(mask, (gray.shape[1], gray.shape[0]))\n",
        "    masked_image = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "\n",
        "\n",
        "    gray = masked_image\n",
        "    radius = 1\n",
        "    n_points = 8 * radius\n",
        "\n",
        "    lbp, lbp_features = extract_lbp_features(gray, radius, n_points, method='uniform')\n",
        "\n",
        "    hog_features = hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys')\n",
        "\n",
        "    features = np.concatenate((lbp_features, hog_features))\n",
        "\n",
        "    features_list.append(features)\n",
        "\n",
        "features_array = np.array(features_list, dtype=object)\n",
        "\n",
        "save_path = r\"/content/drive/MyDrive/students_data/TEST1_features_array_gun.npy\"\n",
        "np.save(save_path, features_array)\n",
        "\n",
        "print(\"Features Array Shape:\", features_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErDBGkgFRqlh",
        "outputId": "df9bafd9-dacd-4a0a-b309-ea9ce5c8ff3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Array Shape: (93, 142894)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Knives (pre processing)**\n",
        "*Creating features Array*\n",
        "\n",
        "Run once for creating training arrays, then for Testing arrays.\n",
        "\n"
      ],
      "metadata": {
        "id": "i8YDde8eR8LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_lbp_features(image, radius=1, n_points=8, method='uniform'):\n",
        "    lbp = local_binary_pattern(image, n_points, radius, method=method)\n",
        "    n_bins = int(lbp.max() + 1)\n",
        "    lbp_hist, _ = np.histogram(lbp, bins=n_bins, range=(0, n_bins), density=True)\n",
        "    return lbp, lbp_hist\n",
        "#for testing\n",
        "folder_path = r\"/content/drive/MyDrive/students_data/test/knife\"\n",
        "mask_folder_path = r\"/content/drive/MyDrive/students_data/test/annotations/knife\"\n",
        "\n",
        "\n",
        "#for trraining\n",
        "#folder_path = r\"/content/drive/MyDrive/students_data/train/knife\"\n",
        "#mask_folder_path = r\"/content/drive/MyDrive/students_data/train/annotations/knife\"\n",
        "images = os.listdir(folder_path)\n",
        "\n",
        "features_list = []\n",
        "\n",
        "for image_name in images:\n",
        "    image_path = os.path.join(folder_path, image_name)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    image = cv2.resize(image, (512, 512))\n",
        "\n",
        "    mask_path = os.path.join(mask_folder_path, image_name)\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    mask = cv2.resize(mask, (gray.shape[1], gray.shape[0]))\n",
        "    masked_image = cv2.bitwise_and(gray, gray, mask=mask)\n",
        "\n",
        "\n",
        "    gray = masked_image\n",
        "    radius = 1\n",
        "    n_points = 8 * radius\n",
        "\n",
        "    lbp, lbp_features = extract_lbp_features(gray, radius, n_points, method='uniform')\n",
        "\n",
        "    hog_features = hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys')\n",
        "\n",
        "    features = np.concatenate((lbp_features, hog_features))\n",
        "\n",
        "    features_list.append(features)\n",
        "\n",
        "features_array = np.array(features_list, dtype=object)\n",
        "\n",
        "save_path = r\"/content/drive/MyDrive/students_data/TEST2_features_array_knife.npy\"\n",
        "np.save(save_path, features_array)\n",
        "\n",
        "print(\"Features Array Shape:\", features_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSJ_Qz0pR2sj",
        "outputId": "6d05fe16-3835-423b-a310-ce613b73cd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Array Shape: (30, 142894)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Safe (Pre processing)**\n",
        "*Creating feature array*\n",
        "\n",
        "Run once for creating training arrays, then for Testing arrays.\n",
        "\n"
      ],
      "metadata": {
        "id": "6mPGpGvRSKs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_lbp_features(image, radius=1, n_points=8, method='uniform'):\n",
        "    lbp = local_binary_pattern(image, n_points, radius, method=method)\n",
        "    n_bins = int(lbp.max() + 1)\n",
        "    lbp_hist, _ = np.histogram(lbp, bins=n_bins, range=(0, n_bins), density=True)\n",
        "    return lbp, lbp_hist\n",
        "\n",
        "#for testing\n",
        "folder_path = r\"/content/drive/MyDrive/students_data/test/safe\"\n",
        "\n",
        "\n",
        "#for training\n",
        "#folder_path = r\"/content/drive/MyDrive/students_data/train/safe\"\n",
        "images = os.listdir(folder_path)\n",
        "\n",
        "features_list = []\n",
        "\n",
        "for image_name in images:\n",
        "    image_path = os.path.join(folder_path, image_name)\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    image = cv2.resize(image, (512, 512))\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    radius = 1\n",
        "    n_points = 8 * radius\n",
        "\n",
        "    lbp, lbp_features = extract_lbp_features(gray, radius, n_points, method='uniform')\n",
        "\n",
        "    hog_features = hog(gray, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys')\n",
        "\n",
        "    features = np.concatenate((lbp_features, hog_features))\n",
        "\n",
        "    features_list.append(features)\n",
        "\n",
        "features_array = np.array(features_list, dtype=object)\n",
        "\n",
        "save_path = r\"/content/drive/MyDrive/students_data/TEST3_features_array_safe.npy\"\n",
        "np.save(save_path, features_array)\n",
        "\n",
        "print(\"Features Array Shape:\", features_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg08Lt0lSNYQ",
        "outputId": "2772dd49-7c0b-4c88-b04a-ed24f56a762d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Array Shape: (55, 142894)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Loading Training & Testing data for Model**"
      ],
      "metadata": {
        "id": "B3_V6zlzZDqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "X_train_gun = np.load('/content/drive/MyDrive/students_data/features_array_gun.npy', allow_pickle=True)\n",
        "X_train_knife = np.load('/content/drive/MyDrive/students_data/features_array_knife.npy', allow_pickle=True)\n",
        "X_train_safe = np.load('/content/drive/MyDrive/students_data/features_array_safe.npy', allow_pickle=True)\n",
        "\n",
        "# Load testing data\n",
        "X_test_gun = np.load('/content/drive/MyDrive/students_data/TEST1_features_array_gun.npy', allow_pickle=True)\n",
        "X_test_knife = np.load('/content/drive/MyDrive/students_data/TEST2_features_array_knife.npy', allow_pickle=True)\n",
        "X_test_safe = np.load('/content/drive/MyDrive/students_data/TEST3_features_array_safe.npy', allow_pickle=True)\n"
      ],
      "metadata": {
        "id": "hT90o_mCZGMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Creating Labels**"
      ],
      "metadata": {
        "id": "FMjoQOHtZHyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Combine features and labels**"
      ],
      "metadata": {
        "id": "4ciPUaGRZRBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create labels\n",
        "y_train_gun = np.full(X_train_gun.shape[0], 0)  # Label '0' for gun\n",
        "y_train_knife = np.full(X_train_knife.shape[0], 1)  # Label '1' for knife\n",
        "y_train_safe = np.full(X_train_safe.shape[0], 2)  # Label '2' for safe\n",
        "\n",
        "y_test_gun = np.full(X_test_gun.shape[0], 0)  # Label '0' for gun\n",
        "y_test_knife = np.full(X_test_knife.shape[0], 1)  # Label '1' for knife\n",
        "y_test_safe = np.full(X_test_safe.shape[0], 2)  # Label '2' for safe\n",
        "\n",
        "# Combine training data and labels\n",
        "X_train = np.concatenate((X_train_gun, X_train_knife, X_train_safe))\n",
        "y_train = np.concatenate((y_train_gun, y_train_knife, y_train_safe))\n",
        "\n",
        "# Combine testing data and labels\n",
        "X_test = np.concatenate((X_test_gun, X_test_knife, X_test_safe))\n",
        "y_test = np.concatenate((y_test_gun, y_test_knife, y_test_safe))\n"
      ],
      "metadata": {
        "id": "y5Yb_TRcZUwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train SVM Model"
      ],
      "metadata": {
        "id": "rvyx_p7Gf2i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Define the pipeline with PCA for dimensionality reduction\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Standardize the features\n",
        "    ('pca', PCA(n_components=50)),  # Reduce to 50 principal components\n",
        "    ('svc', SVC(probability=True))  # SVM classifier with probability estimates\n",
        "])\n",
        "\n",
        "# Define a smaller parameter grid for GridSearch\n",
        "param_grid = {\n",
        "    'svc__C': [0.1, 1, 10],\n",
        "    'svc__kernel': ['linear', 'rbf'],\n",
        "    'svc__gamma': ['scale']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='accuracy', n_jobs=1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Print best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6PHl2rEf4Od",
        "outputId": "60179e62-1da3-4cef-c53d-78d07a2e8c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Best parameters found:  {'svc__C': 1, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Save The model**"
      ],
      "metadata": {
        "id": "WxYO4UqcunEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Define the path where you want to save the model\n",
        "save_model_path = '/content/drive/MyDrive/students_data/svm_model.pkl'\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(best_model, save_model_path)\n",
        "\n",
        "print(f\"Trained model saved to {save_model_path}\")\n"
      ],
      "metadata": {
        "id": "CevJsvDEuk25",
        "outputId": "44dc4d99-ad6a-4f53-84cc-9f22a0886e41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained model saved to /content/drive/MyDrive/students_data/svm_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate SVM Model"
      ],
      "metadata": {
        "id": "HJkHZJK_f5io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate classification report\n",
        "classification_rep = classification_report(y_test, y_pred, target_names=['Gun', 'Knife', 'Safe'])\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate F1 score for each class\n",
        "f1_scores = f1_score(y_test, y_pred, average=None)\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(conf_matrix, classes=['Gun', 'Knife', 'Safe'])\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Overall Accuracy: {accuracy}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n",
        "print(f\"F1 Scores for each class: {f1_scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "LKONlcwtf7wE",
        "outputId": "82e4dfa9-cf14-4dd1-bc14-89950ced1af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy: 0.9044943820224719\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Gun       0.85      1.00      0.92        93\n",
            "       Knife       1.00      0.47      0.64        30\n",
            "        Safe       1.00      0.98      0.99        55\n",
            "\n",
            "    accuracy                           0.90       178\n",
            "   macro avg       0.95      0.82      0.85       178\n",
            "weighted avg       0.92      0.90      0.89       178\n",
            "\n",
            "F1 Scores for each class: [0.91625616 0.63636364 0.99082569]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqYAAAJhCAYAAACTlnKTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVO0lEQVR4nO3dd3gU9drG8Xs3pJFKTYiEGkWQJkUERDrBI9JURPEQEBSQjtSDdIUjSpEuohRFQUVQQVCkI0hvIkQ6CIQiQkhCCsm8f3Cyr2tAs5JlRvb74ZrrcmdnZ56Je4WHe37zG5thGIYAAAAAk9nNLgAAAACQaEwBAABgETSmAAAAsAQaUwAAAFgCjSkAAAAsgcYUAAAAlkBjCgAAAEugMQUAAIAl0JgCAADAEmhMAZju0KFDatSokUJCQmSz2bRkyZIc3f/x48dls9k0Z86cHN3vP1mdOnVUp04ds8sAACc0pgAkSUeOHFGnTp1UokQJ+fn5KTg4WDVr1tTbb7+ta9euufXYMTEx2rdvn15//XV98MEHqlKliluPdye1a9dONptNwcHBN/05Hjp0SDabTTabTW+99ZbL+z9z5oyGDx+u3bt350C1AGCuXGYXAMB8y5Yt09NPPy1fX1+1bdtWZcuWVWpqqjZu3Kh+/fpp//79mjlzpluOfe3aNW3evFmDBw9Wt27d3HKMokWL6tq1a/L29nbL/v9Krly5lJSUpK+++kqtWrVyem/+/Pny8/NTcnLy39r3mTNnNGLECBUrVkwVK1bM9ue+/fbbv3U8AHAnGlPAwx07dkytW7dW0aJFtXr1ahUqVMjxXteuXXX48GEtW7bMbce/cOGCJCk0NNRtx7DZbPLz83Pb/v+Kr6+vatasqY8//jhLY/rRRx/p8ccf16JFi+5ILUlJScqdO7d8fHzuyPEAwBVcygc83NixY5WQkKD33nvPqSnNFBUVpZ49ezpeX79+XaNGjVLJkiXl6+urYsWK6T//+Y9SUlKcPlesWDE1adJEGzdu1EMPPSQ/Pz+VKFFC8+bNc2wzfPhwFS1aVJLUr18/2Ww2FStWTNKNS+CZ//17w4cPl81mc1q3cuVKPfLIIwoNDVVgYKBKlSql//znP473bzXGdPXq1apVq5YCAgIUGhqqZs2a6cCBAzc93uHDh9WuXTuFhoYqJCRE7du3V1JS0q1/sH/w3HPPafny5bp8+bJj3bZt23To0CE999xzWba/dOmS+vbtq3LlyikwMFDBwcF67LHHtGfPHsc2a9euVdWqVSVJ7du3dwwJyDzPOnXqqGzZstqxY4ceffRR5c6d2/Fz+eMY05iYGPn5+WU5/+joaOXJk0dnzpzJ9rkCwN9FYwp4uK+++kolSpRQjRo1srV9x44dNXToUFWqVEkTJkxQ7dq1NWbMGLVu3TrLtocPH9ZTTz2lhg0baty4ccqTJ4/atWun/fv3S5JatmypCRMmSJKeffZZffDBB5o4caJL9e/fv19NmjRRSkqKRo4cqXHjxqlp06b6/vvv//Rz3333naKjo3X+/HkNHz5cffr00aZNm1SzZk0dP348y/atWrXS1atXNWbMGLVq1Upz5szRiBEjsl1ny5YtZbPZ9PnnnzvWffTRR7r//vtVqVKlLNsfPXpUS5YsUZMmTTR+/Hj169dP+/btU+3atR1NYunSpTVy5EhJ0ksvvaQPPvhAH3zwgR599FHHfn799Vc99thjqlixoiZOnKi6devetL63335bBQoUUExMjNLT0yVJ77zzjr799ltNnjxZERER2T5XAPjbDAAe68qVK4Yko1mzZtnafvfu3YYko2PHjk7r+/bta0gyVq9e7VhXtGhRQ5Kxfv16x7rz588bvr6+xiuvvOJYd+zYMUOS8eabbzrtMyYmxihatGiWGoYNG2b8/lfXhAkTDEnGhQsXbll35jFmz57tWFexYkWjYMGCxq+//upYt2fPHsNutxtt27bNcrwXXnjBaZ8tWrQw8uXLd8tj/v48AgICDMMwjKeeesqoX7++YRiGkZ6eboSHhxsjRoy46c8gOTnZSE9Pz3Ievr6+xsiRIx3rtm3bluXcMtWuXduQZMyYMeOm79WuXdtp3TfffGNIMl577TXj6NGjRmBgoNG8efO/PEcAyCkkpoAHi4+PlyQFBQVla/uvv/5aktSnTx+n9a+88ookZRmLWqZMGdWqVcvxukCBAipVqpSOHj36t2v+o8yxqV988YUyMjKy9ZmzZ89q9+7dateunfLmzetYX758eTVs2NBxnr/XuXNnp9e1atXSr7/+6vgZZsdzzz2ntWvXKi4uTqtXr1ZcXNxNL+NLN8al2u03fkWnp6fr119/dQxT2LlzZ7aP6evrq/bt22dr20aNGqlTp04aOXKkWrZsKT8/P73zzjvZPhYA3C4aU8CDBQcHS5KuXr2are1PnDghu92uqKgop/Xh4eEKDQ3ViRMnnNYXKVIkyz7y5Mmj33777W9WnNUzzzyjmjVrqmPHjgoLC1Pr1q31ySef/GmTmllnqVKlsrxXunRpXbx4UYmJiU7r/3guefLkkSSXzuVf//qXgoKCtHDhQs2fP19Vq1bN8rPMlJGRoQkTJujee++Vr6+v8ufPrwIFCmjv3r26cuVKto95zz33uHSj01tvvaW8efNq9+7dmjRpkgoWLJjtzwLA7aIxBTxYcHCwIiIi9OOPP7r0uT/efHQrXl5eN11vGMbfPkbm+MdM/v7+Wr9+vb777jv9+9//1t69e/XMM8+oYcOGWba9HbdzLpl8fX3VsmVLzZ07V4sXL75lWipJo0ePVp8+ffToo4/qww8/1DfffKOVK1fqgQceyHYyLN34+bhi165dOn/+vCRp3759Ln0WAG4XjSng4Zo0aaIjR45o8+bNf7lt0aJFlZGRoUOHDjmtP3funC5fvuy4wz4n5MmTx+kO9kx/TGUlyW63q379+ho/frx++uknvf7661q9erXWrFlz031n1hkbG5vlvYMHDyp//vwKCAi4vRO4heeee067du3S1atXb3rDWKbPPvtMdevW1XvvvafWrVurUaNGatCgQZafSXb/kZAdiYmJat++vcqUKaOXXnpJY8eO1bZt23Js/wDwV2hMAQ/Xv39/BQQEqGPHjjp37lyW948cOaK3335b0o1L0ZKy3Dk/fvx4SdLjjz+eY3WVLFlSV65c0d69ex3rzp49q8WLFzttd+nSpSyfzZxo/o9TWGUqVKiQKlasqLlz5zo1ej/++KO+/fZbx3m6Q926dTVq1ChNmTJF4eHht9zOy8srSxr76aef6vTp007rMhvomzXxrhowYIBOnjypuXPnavz48SpWrJhiYmJu+XMEgJzGBPuAhytZsqQ++ugjPfPMMypdurTTk582bdqkTz/9VO3atZMkVahQQTExMZo5c6YuX76s2rVra+vWrZo7d66aN29+y6mI/o7WrVtrwIABatGihXr06KGkpCRNnz5d9913n9PNPyNHjtT69ev1+OOPq2jRojp//rymTZumwoUL65FHHrnl/t9880099thjql69ujp06KBr165p8uTJCgkJ0fDhw3PsPP7Ibrfr1Vdf/cvtmjRpopEjR6p9+/aqUaOG9u3bp/nz56tEiRJO25UsWVKhoaGaMWOGgoKCFBAQoGrVqql48eIu1bV69WpNmzZNw4YNc0xfNXv2bNWpU0dDhgzR2LFjXdofAPwdJKYA1LRpU+3du1dPPfWUvvjiC3Xt2lUDBw7U8ePHNW7cOE2aNMmx7axZszRixAht27ZNvXr10urVqzVo0CAtWLAgR2vKly+fFi9erNy5c6t///6aO3euxowZoyeeeCJL7UWKFNH777+vrl27aurUqXr00Ue1evVqhYSE3HL/DRo00IoVK5QvXz4NHTpUb731lh5++GF9//33Ljd17vCf//xHr7zyir755hv17NlTO3fu1LJlyxQZGem0nbe3t+bOnSsvLy917txZzz77rNatW+fSsa5evaoXXnhBDz74oAYPHuxYX6tWLfXs2VPjxo3TDz/8kCPnBQB/xma4MnIfAAAAcBMSUwAAAFgCjSkAAAAsgcYUAAAAlkBjCgAAAEugMQUAAIAl0JgCAADAEphgPxsyMjJ05swZBQUF5ejj/wAAgHkMw9DVq1cVEREhu91aWV1ycrJSU1PdegwfHx/5+fm59RiuojHNhjNnzmSZ1BoAANwdTp06pcKFC5tdhkNycrL8g/JJ15Pcepzw8HAdO3bMUs0pjWk2BAUFSZJ8ysTI5uVjcjVAVifXvmV2CQDwj3M1Pl5RxSMdf89bRWpqqnQ9Sb5lYiR39R3pqYr7aa5SU1NpTP9pMi/f27x8aExhScHBwWaXAAD/WJYdppfLz219h2Gz1tCFTNasCgAAAB6HxBQAAMCKbJLcleZaNCQmMQUAAIAlkJgCAABYkc1+Y3HXvi3ImlUBAADA45CYAgAAWJHN5sYxptYcZEpiCgAAAEsgMQUAALAixpgCAAAA5iAxBQAAsCLGmAIAAADmIDEFAACwJDeOMbVoNmnNqgAAAOBxSEwBAACsyAPHmNKYAgAAWBHTRQEAAADmIDEFAACwIg+8lE9iCgAAAEsgMQUAALAixpgCAAAA5iAxBQAAsCLGmAIAAADmIDEFAACwIsaYAgAAAOYgMQUAALAim82NiSljTAEAAIBbIjEFAACwIrvtxuKufVsQiSkAAAAsgcQUAADAirgrHwAAADAHiSkAAIAV8eQnAAAAwBwkpgAAAFbEGFMAAADAHCSmAAAAVsQYUwAAAMAcJKYAAABWxBhTAAAAwBwkpgAAAFbEGFMAAADAHCSmAAAAVsQYUwAAAMAcJKYAAABWxBhTAAAAwBwkpgAAAJbkxjGmFs0mrVkVAAAAPA6JKQAAgBUxxhQAAAAwB4kpAACAFdlsbpzHlMQUAAAAuCUSUwAAACviyU8AAACAOUhMAQAArIi78gEAAABzkJgCAABYEWNMAQAAAHOQmAIAAFgRY0wBAAAAc5CYAgAAWBFjTAEAAABzkJgCAABYEWNMAQAAAHOQmAIAAFiQzWaTjcQUAAAAuCE9PV1DhgxR8eLF5e/vr5IlS2rUqFEyDMOxjWEYGjp0qAoVKiR/f381aNBAhw4dcvlYNKYAAAAWlJmYumvJrjfeeEPTp0/XlClTdODAAb3xxhsaO3asJk+e7Nhm7NixmjRpkmbMmKEtW7YoICBA0dHRSk5OdumcuZQPAACAW9q0aZOaNWumxx9/XJJUrFgxffzxx9q6daukG2npxIkT9eqrr6pZs2aSpHnz5iksLExLlixR69ats30sElMAAAArsrl5kRQfH++0pKSkZCmjRo0aWrVqlX7++WdJ0p49e7Rx40Y99thjkqRjx44pLi5ODRo0cHwmJCRE1apV0+bNm106ZRJTAAAADxUZGen0etiwYRo+fLjTuoEDByo+Pl7333+/vLy8lJ6ertdff11t2rSRJMXFxUmSwsLCnD4XFhbmeC+7aEwBAAAs6E7clX/q1CkFBwc7Vvv6+mbZ9JNPPtH8+fP10Ucf6YEHHtDu3bvVq1cvRUREKCYmJkfLojEFAADwUMHBwU6N6c3069dPAwcOdIwVLVeunE6cOKExY8YoJiZG4eHhkqRz586pUKFCjs+dO3dOFStWdKkexpgCAABYkFXuyk9KSpLd7twyenl5KSMjQ5JUvHhxhYeHa9WqVY734+PjtWXLFlWvXt2lc6YxhdsE5vbVm32fVOzXI3Vp83itmdNHlcsUcbw/uNO/tPvzV3Vx0zidWTdWy2Z0U9WyRU2sGJBmTJuqUlHFFBrop1o1qmnb/+46BczGd9PzWKUxfeKJJ/T6669r2bJlOn78uBYvXqzx48erRYsWjjp79eql1157TV9++aX27duntm3bKiIiQs2bN3fpnGlM4TbThz6neg/frxdenasqrUbru80HtWxGd0UUCJEkHT5xXr3f+FRVnh6t+u3H68SZS/pqWjflzxNocuXwVJ9+slAD+vXR4FeHafPWnSpfvoKaPh6t8+fPm10aPBzfTZhp8uTJeuqpp/Tyyy+rdOnS6tu3rzp16qRRo0Y5tunfv7+6d++ul156SVWrVlVCQoJWrFghPz8/l45lM34/bT9uKj4+XiEhIfIt96JsXj5ml/OP4OfrrQsb39LTvWdqxcb9jvXfz++vb7//SSOmLc3ymaAAP53f+JYe6zRJa7f+fCfL/cf7bdsUs0u4K9SqUU2Vq1TVxEk3fp4ZGRmKKh6pLl27q1//gSZXB0/Gd9M94uPjFZYvRFeuXPnLcZZ3UmbfEfTkO7J5+7vlGEbaNV1d1Mly505iCrfI5WVXrlxeSk5Nc1qfnJKmGg+WzLK9dy4vdWhZU5evJmnfz6fvVJmAQ2pqqnbt3KF69f9/Hj673a569Rpo6w+uzcMH5CS+m/Ak3JUPt0hIStEPe45q0IuPKfbYOZ37NV6tGldRtfLFdeTUBcd2j9Uqq3n/ba/cft6KuxivJp2n6NfLiSZWDk918eJFpaenq2BB53n4CoaFKTb2oElVAXw3PdrvJsJ3y74tiMQUbvPCq/Nks0lHv31dV7ZMVNdna+uTFduVkfH/o0fWbftZ1VqPUd124/Xtpp/04dgXVIAxpgAAeCRLN6ZxcXHq2bOnoqKi5Ofnp7CwMNWsWVPTp09XUlKS2eXhLxz75aIadXxb+ar30b2PDVGtf78l71xeOnb6omObpORUHT11UVv3HVeXER/penqGYlrUMLFqeKr8+fPLy8tL58+fc1p//tw5xxx9gBn4bnouq9yVfydZtjE9evSoHnzwQX377bcaPXq0du3apc2bN6t///5aunSpvvvuO7NLRDYlJacq7mK8QoP81aBGaS1du++W29ptNvl6M8IEd56Pj48erFRZa1b//zx8GRkZWrNmlR562LV5+ICcxHcTnsSyHcDLL7+sXLlyafv27QoICHCsL1GihJo1aybDMHT8+HEVL15cu3btcjxZ4PLly8qTJ4/WrFmjOnXqaO3atapbt66+++47DRgwQD/99JMqVqyo2bNnq1SpUiadnWdoUL20bDbp5+PnVTKygEb3bq6fj53TvC83K7efjwZ0jNaydfsUd/GK8oUGqlOrRxVRMFSfr9xpdunwUD169dGLL8SocuUqqlL1IU2ZNFFJiYlqG9Pe7NLg4fhueiabTW58JKl7dnu7LNmY/vrrr46k9PdN6e+5+j9q8ODBGjdunAoUKKDOnTvrhRde0Pfff3/TbVNSUpSSkuJ4HR8f79KxcENIoJ9Gdm+qe8JCdelKkr5YtVvDpn6l69cz5GXPUKliYXr+iWrKFxqgS1eStH3/CTV4YYIOHI0zu3R4qKdbPaOLFy5o5IihOhcXp/IVKuqLpSsUFhb21x8G3IjvJjyFJRvTw4cPyzCMLIlm/vz5lZycLEnq2rWrunTpku19vv7666pdu7YkaeDAgXr88ceVnJx804lfx4wZoxEjRtzGGUCSFq3cpUUrd930vZTU62rdd9Ydrgj4a126dlOXrt3MLgPIgu+m57HJnWNBrRmZWnaM6c1s3bpVu3fv1gMPPOCUaGZH+fLlHf9dqFAhSbrlEzMGDRqkK1euOJZTp079/aIBAACQLZZMTKOiomSz2RQbG+u0vkSJEpIkf/8bT0Gw22/01b9/eFVamvOE7pm8vb0d/535r4+MjIybbuvr6ytfX9+/WT0AAMDtc+vd89yVn3358uVTw4YNNWXKFCUm3nqy9QIFCkiSzp4961i3e/dud5cHAAAAN7BkYypJ06ZN0/Xr11WlShUtXLhQBw4cUGxsrD788EMdPHhQXl5e8vf318MPP6z//ve/OnDggNatW6dXX33V7NIBAABun83NiwVZ8lK+JJUsWVK7du3S6NGjNWjQIP3yyy/y9fVVmTJl1LdvX7388suSpPfff18dOnRQ5cqVVapUKY0dO1aNGjUyuXoAAAC4ymb8foAmbio+Pl4hISHyLfeibF4+ZpcDZPHbtilmlwAA/zjx8fEKyxeiK1euKDg42OxyHDL7jjzPvie7T263HCMjNUm/fdzBcudu2Uv5AAAA8CyWvZQPAADgydx5V7775ke9PSSmAAAAsAQSUwAAAAsiMQUAAABMQmIKAABgRe6cb9SagSmJKQAAAKyBxBQAAMCCGGMKAAAAmITEFAAAwIJITAEAAACTkJgCAABYEIkpAAAAYBISUwAAAAsiMQUAAABMQmIKAABgRTz5CQAAADAHiSkAAIAFMcYUAAAAMAmJKQAAgAWRmAIAAAAmITEFAACwIBJTAAAAwCQkpgAAAFbEPKYAAACAOUhMAQAALIgxpgAAAIBJSEwBAAAsiMQUAAAAMAmJKQAAgAXZ5MbE1KK35ZOYAgAAwBJITAEAACyIMaYAAACASUhMAQAArIgnPwEAAADmIDEFAACwIMaYAgAAACYhMQUAALAgElMAAADAJCSmAAAAFmSz3VjctW8rojEFAACwoBuNqbsu5btlt7eNS/kAAACwBBJTAAAAK3LjpXwm2AcAAAD+BIkpAACABTFdFAAAAGASElMAAAAL8sTpokhMAQAAYAkkpgAAABZkt9tkt7sn2jTctN/bRWIKAAAASyAxBQAAsCDGmAIAAAAmITEFAACwIOYxBQAAAExCYgoAAGBBjDEFAAAATEJiCgAAYEGMMQUAAABMQmIKAABgQSSmAAAAgElITAEAACyIu/IBAAAAk5CYAgAAWJBNbhxjKmtGpiSmAAAAsAQSUwAAAAtijCkAAABgEhJTAAAAC2IeUwAAAMAkJKYAAAAWxBhTAAAAwCQkpgAAABbEGFMAAADAJCSmAAAAFsQYUwAAAMAkJKYAAAAWxBhTAAAAwCQkpi5Y98lwBQYFm10GkMXJi0lmlwDcUpH8uc0uAfhncuMYU1kzMCUxBQAAgDWQmAIAAFgQY0wBAAAAk5CYAgAAWBDzmAIAAAAmITEFAACwIMaYAgAAAH9w+vRpPf/888qXL5/8/f1Vrlw5bd++3fG+YRgaOnSoChUqJH9/fzVo0ECHDh1y+Tg0pgAAABaUOcbUXUt2/fbbb6pZs6a8vb21fPly/fTTTxo3bpzy5Mnj2Gbs2LGaNGmSZsyYoS1btiggIEDR0dFKTk526Zy5lA8AAIBbeuONNxQZGanZs2c71hUvXtzx34ZhaOLEiXr11VfVrFkzSdK8efMUFhamJUuWqHXr1tk+FokpAACABWWOMXXXIknx8fFOS0pKSpY6vvzyS1WpUkVPP/20ChYsqAcffFDvvvuu4/1jx44pLi5ODRo0cKwLCQlRtWrVtHnzZpfOmcYUAADAQ0VGRiokJMSxjBkzJss2R48e1fTp03Xvvffqm2++UZcuXdSjRw/NnTtXkhQXFydJCgsLc/pcWFiY473s4lI+AACABd2Ju/JPnTql4OBgx3pfX98s22ZkZKhKlSoaPXq0JOnBBx/Ujz/+qBkzZigmJiZH6yIxBQAA8FDBwcFOy80a00KFCqlMmTJO60qXLq2TJ09KksLDwyVJ586dc9rm3Llzjveyi8YUAADAgqxyV37NmjUVGxvrtO7nn39W0aJFJd24ESo8PFyrVq1yvB8fH68tW7aoevXqLp0zl/IBAABwS71791aNGjU0evRotWrVSlu3btXMmTM1c+ZMSTeGBfTq1Uuvvfaa7r33XhUvXlxDhgxRRESEmjdv7tKxaEwBAAAsyCpPfqpataoWL16sQYMGaeTIkSpevLgmTpyoNm3aOLbp37+/EhMT9dJLL+ny5ct65JFHtGLFCvn5+blUF40pAAAA/lSTJk3UpEmTW75vs9k0cuRIjRw58raOQ2MKAABgQa6OBXV131bEzU8AAACwBBJTAAAAC7LKGNM7icYUAADAgmxy46V89+z2tnEpHwAAAJZAYgoAAGBBdptNdjdFpu7a7+0iMQUAAIAlkJgCAABYENNFAQAAACYhMQUAALAgT5wuisQUAAAAlkBiCgAAYEF2243FXfu2IhJTAAAAWAKJKQAAgBXZ3DgWlMQUAAAAuDUSUwAAAAtiHlMAAADAJCSmAAAAFmT73x937duKSEwBAABgCSSmAAAAFsQ8pgAAAIBJSEwBAAAsyGazuW0eU7fNj3qbSEwBAABgCSSmAAAAFsQ8pgAAAIBJSEwBAAAsyG6zye6maNNd+71dJKYAAACwBBJTAAAAC2KMKQAAAGASElMAAAALYh5TAAAAwCQkpgAAABbEGFMAAADAJCSmAAAAFsQ8pgAAAIBJspWYfvnll9neYdOmTf92MQAAALjB9r/FXfu2omw1ps2bN8/Wzmw2m9LT02+nHgAAAHiobDWmGRkZ7q4DAAAAv8M8pi5KTk7OqToAAADg4VxuTNPT0zVq1Cjdc889CgwM1NGjRyVJQ4YM0XvvvZfjBQIAAHgiu829ixW53Ji+/vrrmjNnjsaOHSsfHx/H+rJly2rWrFk5WhwAAAA8h8uN6bx58zRz5ky1adNGXl5ejvUVKlTQwYMHc7Q4AAAAT5U5xtRdixW53JiePn1aUVFRWdZnZGQoLS0tR4oCAACA53G5MS1Tpow2bNiQZf1nn32mBx98MEeKAgAAwI1n2rtjsSqXH0k6dOhQxcTE6PTp08rIyNDnn3+u2NhYzZs3T0uXLnVHjQAAAPAALiemzZo101dffaXvvvtOAQEBGjp0qA4cOKCvvvpKDRs2dEeNAAAAHscTx5i6nJhKUq1atbRy5cqcrgUAAAAe7G81ppK0fft2HThwQNKNcaeVK1fOsaIAAAA8nTvnG7XqPKYuN6a//PKLnn32WX3//fcKDQ2VJF2+fFk1atTQggULVLhw4ZyuEQAAAB7A5TGmHTt2VFpamg4cOKBLly7p0qVLOnDggDIyMtSxY0d31AgAAOBxGGOaDevWrdOmTZtUqlQpx7pSpUpp8uTJqlWrVo4WBwAAAM/hcmMaGRl504n009PTFRERkSNFAQAAeDrb/xZ37duKXL6U/+abb6p79+7avn27Y9327dvVs2dPvfXWWzlaHAAAADxHthLTPHnyOI1FSExMVLVq1ZQr142PX79+Xbly5dILL7yg5s2bu6VQAAAAT2K32WR301hQd+33dmWrMZ04caKbywAAAICny1ZjGhMT4+46AAAA8DvufK69RQPTvz/BviQlJycrNTXVaV1wcPBtFQQAAADP5PLNT4mJierWrZsKFiyogIAA5cmTx2kBMm3/YaO6tntadSvfq7KFg7RqxVdZtjly6KC6tW+lh0vfo6r3humZx2vr7OlTJlQLT7Nt80Z1bvuUHqlYUqUKBei75Vm/n5mG9u+hUoUCNGfmlDtYIeBsxrSpKhVVTKGBfqpVo5q2bd1qdklwM0+cx9TlxrR///5avXq1pk+fLl9fX82aNUsjRoxQRESE5s2b544a8Q91LSlJpcqU0+DXxt30/ZPHj6pti0YqXvI+zf70ay1auVmde/aXj6/fHa4UnigpKVGlypTTsNET/nS7lV9/qT07t6pgeKE7VBmQ1aefLNSAfn00+NVh2rx1p8qXr6Cmj0fr/PnzZpcG5CiXL+V/9dVXmjdvnurUqaP27durVq1aioqKUtGiRTV//ny1adPGHXXiH6hWvUaqVa/RLd+fNHakatWL1iuvvuZYV6RYiTtRGqDa9aNVu370n25z7uwZjXr1Fb338Rfq9PyTd6gyIKtJE8erfYcX1bZde0nS5GkztHz5Ms2d87769R9ocnVwF08cY+pyYnrp0iWVKHGjeQgODtalS5ckSY888ojWr1+fs9XhrpWRkaH1q75RsRJReqlNcz1aobiebVL3ppf7ATNkZGSoX/cO6tCll+4tVcbscuDBUlNTtWvnDtWr38Cxzm63q169Btr6w2YTK4O7ZU4X5a7FilxuTEuUKKFjx45Jku6//3598sknkm4kqaGhoTlaXHbYbDYtWbLE8frgwYN6+OGH5efnp4oVK97xepA9ly5eUFJigt6bOl6P1GmgmR99ofqNm6jXi220bfNGs8sD9O6UccrllUttO75sdinwcBcvXlR6eroKFgxzWl8wLExxcXEmVQW4h8uNafv27bVnzx5J0sCBAzV16lT5+fmpd+/e6tevn0v7ateuXZYJ+T/77DP5+flp3Libj0v8o7Nnz+qxxx5zvB42bJgCAgIUGxurVatWuVQP7pyMjAxJUt1Gj6vti910/wPl1bHbK6rdoLE++fA9k6uDp/txzy7NmzVNY96eadkbBADc/TIv5btrsSKXx5j27t3b8d8NGjTQwYMHtWPHDkVFRal8+fK3VcysWbPUtWtXzZgxQ+3bt8/WZ8LDw51eHzlyRI8//riKFi16W7XAvfLkzadcuXKp5H33O60vEVVKO7dxaQrm2r7le/168YLqVinlWJeenq43RgzSvHenavW2AyZWB0+TP39+eXl56fz5c07rz587l+XvQOCfzuXE9I+KFi2qli1b3nZTOnbsWHXv3l0LFixwNKV16tRRjx491L9/f+XNm1fh4eEaPny40+d+fynfZrNpx44dGjlypGw2m2PbU6dOqVWrVgoNDVXevHnVrFkzHT9+/Lbqxe3x9vHRAxUq6diRQ07rjx89rIh7iphUFXBDs6ee1Zert2jJd5sdS8HwQurwci/N+vgLs8uDh/Hx8dGDlSprzer/vwqYkZGhNWtW6aGHq5tYGdzNE6eLylZiOmnSpGzvsEePHi4XMWDAAE2bNk1Lly5V/fr1nd6bO3eu+vTpoy1btmjz5s1q166datasqYYNG2bZz9mzZ9WgQQM1btxYffv2VWBgoNLS0hQdHa3q1atrw4YNypUrl1577TU1btxYe/fulY+PT5b9pKSkKCUlxfE6Pj7e5XOClJSYoJPHjzpenz51Qgf371VIaB4VuidS7Tv3VN+X26lKtRp6qMaj2rj2O637brlmf/q1iVXDUyQmJujksSOO17+cPK4DP+5RSGheRRSOVJ68+Zy2987lrfwFwlQi6r47XSqgHr366MUXYlS5chVVqfqQpkyaqKTERLWNyd7VReCfIluN6YQJfz7PXyabzeZyY7p8+XJ98cUXWrVqlerVq5fl/fLly2vYsGGSpHvvvVdTpkzRqlWrbtqYhoeHK1euXAoMDHRc3vjwww+VkZGhWbNmOf51MHv2bIWGhmrt2rVq1CjrdEZjxozRiBEjXDoPZPXjnl16odW/HK/HjhgkSWr29HN6fcI7avBYUw0dM1GzpozXmKH9VazkvZow80NVeqiGWSXDg/y4Z6faPvn/49PHDL8x5U6LVm3037dnmlUWcFNPt3pGFy9c0MgRQ3UuLk7lK1TUF0tXKCws7K8/jH8su3Lg0vaf7NuKstWYZt6F7w7ly5fXxYsXNWzYMD300EMKDAzM8v7vFSpUyKUJhffs2aPDhw8rKCjIaX1ycrKOHDly088MGjRIffr0cbyOj49XZGRkto+JGx6qUUs//nL1T7dp2bqtWrZue4cqAv5ftRqPKvZsYra3Z1wpzNalazd16drN7DIAt3L55qecds899+izzz5T3bp11bhxYy1fvtypifT29nba3mazOe7ozo6EhARVrlxZ8+fPz/JegQIFbvoZX19f+fr6ZvsYAAAAOc2dY0GtOsbUEklu0aJFtW7dOsXFxalx48a6evXPUzZXVKpUSYcOHVLBggUVFRXltISEhOTYcQAAAHB7LNGYSlJkZKTWrl2r8+fPKzo6OsduOGrTpo3y58+vZs2aacOGDTp27JjWrl2rHj166JdffsmRYwAAAOQ0m02yu2mxaGBqncZUkgoXLqy1a9fq4sWLOdac5s6dW+vXr1eRIkXUsmVLlS5dWh06dFBycrKCg4NzoGoAAADkBFPHmM6ZMyfLunvuuUc///zzLT/z+8ePSpJhGE6vd+/eneUz4eHhmjt37t8pEQAAwBSZ6aa79m1Ffysx3bBhg55//nlVr15dp0+fliR98MEH2riRZ5wDAADg73G5MV20aJGio6Pl7++vXbt2OSaiv3LlikaPHp3jBQIAAHgiT3zyk8uN6WuvvaYZM2bo3XffdZrKqWbNmtq5c2eOFgcAAADP4fIY09jYWD366KNZ1oeEhOjy5cs5URMAAIDHY4xpNoSHh+vw4cNZ1m/cuFElSpTIkaIAAADgeVxuTF988UX17NlTW7Zskc1m05kzZzR//nz17dtXXbp0cUeNAAAAHsdmc+9iRS5fyh84cKAyMjJUv359JSUl6dFHH5Wvr6/69u2r7t27u6NGAAAAeACXG1ObzabBgwerX79+Onz4sBISElSmTBkFBga6oz4AAACPZLfZZHdTtOmu/d6uvz3Bvo+Pj8qUKZOTtQAAAMCDudyY1q1b90/nvlq9evVtFQQAAIAbNwK569nxlnom/e+43JhWrFjR6XVaWpp2796tH3/8UTExMTlVFwAAADyMy43phAkTbrp++PDhSkhIuO2CAAAA4N675y06xDTnktznn39e77//fk7tDgAAAB7mb9/89EebN2+Wn59fTu0OAADAo9nlxrvyZc3I1OXGtGXLlk6vDcPQ2bNntX37dg0ZMiTHCgMAAIBncbkxDQkJcXptt9tVqlQpjRw5Uo0aNcqxwgAAADyZJ44xdakxTU9PV/v27VWuXDnlyZPHXTUBAADAA7l085OXl5caNWqky5cvu6kcAAAASJLd5t7Fily+K79s2bI6evSoO2oBAACAB3O5MX3ttdfUt29fLV26VGfPnlV8fLzTAgAAgNtns914pr07ln/8GNORI0fqlVde0b/+9S9JUtOmTZ0eTWoYhmw2m9LT03O+SgAAANz1st2YjhgxQp07d9aaNWvcWQ8AAADEXfl/yjAMSVLt2rXdVgwAAAA8l0vTRdms2l4DAADcZdx597xV78p3qTG97777/rI5vXTp0m0VBAAAAM/kUmM6YsSILE9+AgAAQM6z/e+Pu/b9d/33v//VoEGD1LNnT02cOFGSlJycrFdeeUULFixQSkqKoqOjNW3aNIWFhbm0b5ca09atW6tgwYIuHQAAAAB3h23btumdd95R+fLlndb37t1by5Yt06effqqQkBB169ZNLVu21Pfff+/S/rM9jynjSwEAAO4cqz35KSEhQW3atNG7777r9Gj6K1eu6L333tP48eNVr149Va5cWbNnz9amTZv0ww8/uHbO2d0w8658AAAA3B3++KCklJSUW27btWtXPf7442rQoIHT+h07digtLc1p/f33368iRYpo8+bNLtWT7Uv5GRkZLu0YAAAAf9+duCs/MjLSaf2wYcM0fPjwLNsvWLBAO3fu1LZt27K8FxcXJx8fH4WGhjqtDwsLU1xcnEt1uTTGFAAAAHePU6dOKTg42PHa19f3ptv07NlTK1eulJ+fn1vroTEFAACwIJvN5rZ7fDL3Gxwc7NSY3syOHTt0/vx5VapUybEuPT1d69ev15QpU/TNN98oNTVVly9fdkpNz507p/DwcJfqojEFAADALdWvX1/79u1zWte+fXvdf//9GjBggCIjI+Xt7a1Vq1bpySeflCTFxsbq5MmTql69ukvHojEFAACwIKs8+SkoKEhly5Z1WhcQEKB8+fI51nfo0EF9+vRR3rx5FRwcrO7du6t69ep6+OGHXaqLxhQAAAC3ZcKECbLb7XryySedJth3FY0pAACABdlsNxZ37ft2rF271um1n5+fpk6dqqlTp97WfrM9jykAAADgTiSmAAAAFmS32WR3U2Tqrv3eLhJTAAAAWAKJKQAAgAVZ5a78O4nEFAAAAJZAYgoAAGBFbrwrXySmAAAAwK2RmAIAAFiQXTbZ3RRtumu/t4vGFAAAwIKsPMG+u3ApHwAAAJZAYgoAAGBBTBcFAAAAmITEFAAAwIJ4JCkAAABgEhJTAAAAC+KufAAAAMAkJKYAAAAWZJcbx5hadIJ9ElMAAABYAokpAACABTHGFAAAADAJiSkAAIAF2eW+BNGqyaRV6wIAAICHITEFAACwIJvNJpubBoO6a7+3i8QUAAAAlkBiCgAAYEG2/y3u2rcVkZgCAADAEkhMAQAALMhuc+OTnxhjCgAAANwaiSkAAIBFWTPXdB8SUwAAAFgCiSkAAIAF2Wzue6a9RYeYkpgCAADAGkhMAQAALIgnPwEAAAAmITEFAACwILvclyBaNZm0al0AAADwMCSmAAAAFsQYUwAAAMAkJKYAAAAWZJP7nvxkzbyUxBQAAAAWQWIKAABgQZ44xpTG1AVF8wcoODjA7DKALOx2a/6CASTp2TnbzS4BuKm0awlml4A/oDEFAACwIOYxBQAAAExCYgoAAGBBnjjGlMQUAAAAlkBiCgAAYEHMYwoAAACYhMQUAADAgmy2G4u79m1FJKYAAACwBBJTAAAAC7LLJrubRoO6a7+3i8QUAAAAlkBiCgAAYEGMMQUAAABMQmIKAABgQbb//XHXvq2IxBQAAACWQGIKAABgQYwxBQAAAExCYgoAAGBBNjfOY8oYUwAAAOBPkJgCAABYEGNMAQAAAJOQmAIAAFgQiSkAAABgEhJTAAAAC/LEJz/RmAIAAFiQ3XZjcde+rYhL+QAAALAEElMAAAAL8sRL+SSmAAAAsAQSUwAAAAtiuigAAADAJCSmAAAAFmST+8aCWjQwJTEFAACANZCYAgAAWBDzmAIAAAAmITEFAACwIOYxBQAAAExCYgoAAGBBzGMKAAAAmITEFAAAwIJsct98oxYNTElMAQAAYA0kpgAAABZkl012Nw0GtVs0MyUxBQAAgCWQmAIAAFgQY0wBAAAAk5CYAgAAWJEHRqYkpgAAALAEElMAAAALsv3vj7v2bUUkpgAAALAEElMAAAArsrnxmfbWDExJTAEAAGANJKYAAAAW5IE35ZOYAgAAwBpITAEAAKzIAyNTElMAAABYAokpAACABTGPKQAAAGASGlMAAAALstncu2TXmDFjVLVqVQUFBalgwYJq3ry5YmNjnbZJTk5W165dlS9fPgUGBurJJ5/UuXPnXD5nGlMAAADc0rp169S1a1f98MMPWrlypdLS0tSoUSMlJiY6tundu7e++uorffrpp1q3bp3OnDmjli1bunwsxpgCAABYkFVuyl+xYoXT6zlz5qhgwYLasWOHHn30UV25ckXvvfeePvroI9WrV0+SNHv2bJUuXVo//PCDHn744Wwfi8QUAADAQ8XHxzstKSkpf/mZK1euSJLy5s0rSdqxY4fS0tLUoEEDxzb333+/ihQpos2bN7tUD40pAACAFdncvEiKjIxUSEiIYxkzZsyflpSRkaFevXqpZs2aKlu2rCQpLi5OPj4+Cg0Nddo2LCxMcXFxLp0yl/IBAAA81KlTpxQcHOx47evr+6fbd+3aVT/++KM2btzolnpoTAEAACzoTsxjGhwc7NSY/plu3bpp6dKlWr9+vQoXLuxYHx4ertTUVF2+fNkpNT137pzCw8NdqotL+QAAALglwzDUrVs3LV68WKtXr1bx4sWd3q9cubK8vb21atUqx7rY2FidPHlS1atXd+lYJKYAAAAW5Op8o67uO7u6du2qjz76SF988YWCgoIc40ZDQkLk7++vkJAQdejQQX369FHevHkVHBys7t27q3r16i7dkS/RmAIAAOBPTJ8+XZJUp04dp/WzZ89Wu3btJEkTJkyQ3W7Xk08+qZSUFEVHR2vatGkuH4vGFAAAwIKsMo+pYRh/uY2fn5+mTp2qqVOn/v2ixBhTAAAAWASJKQAAgBVZJTK9g0hMAQAAYAkkpgAAABZ0J+YxtRoSUwAAAFgCiSkAAIAFWWUe0zuJxBQAAACWQGIKAABgQR54Uz6JKe6cjRvW66kWTVWy2D0K8LXrqy+WmF0SkMWMaVNVKqqYQgP9VKtGNW3butXskuBhnqkUocUdqzgtk5964KbbDom+V4s7VtFDRUPvbJGAm5CY4o5JTExUufLl1bZdez3b6kmzywGy+PSThRrQr48mT52hqg9V05RJE9X08Wjt2R+rggULml0ePMjJS9c0bHms43V6RtZtnigbpr9+Hg/+0TwwMiUxxR0T3fgxDRvxmpo2a2F2KcBNTZo4Xu07vKi27dqrdJkymjxthvxz59bcOe+bXRo8TLph6PK1647lasp1p/eL5fVX03JhmrL+mEkVAu5BYgoAklJTU7Vr5w71GzDIsc5ut6tevQba+sNmEyuDJyoU7Kv3ni2v1HRDsecT9OG207qYmCpJ8vGyq0/dEnr3+5O6fO36X+wJ/2TMY3qXWLJkiaKiouTl5aVevXqZXQ6Af4CLFy8qPT1dBQuGOa0vGBamuLg4k6qCJzp0PkGT1x/XyG8O6Z3vTygsyFevNyklP+8bf2W/8HCkDp5P0NaTl80tFHADyzWmFy5cUJcuXVSkSBH5+voqPDxc0dHR+v7777O9j06dOumpp57SqVOnNGrUKDdWCwBAztr5S7w2HftNJy5d0+7T8Rr1zSEF+HqpZvG8qlokROUigvT+5lNml4k7IHMeU3ctVmS5S/lPPvmkUlNTNXfuXJUoUULnzp3TqlWr9Ouvv2br8wkJCTp//ryio6MVERHh5moB3C3y588vLy8vnT9/zmn9+XPnFB4eblJVgJSUmq4zV1JUKNhXRfP6KzzYVx+2fdBpm/71S+rAuQQNWRZ7i73gn8gD732yVmJ6+fJlbdiwQW+88Ybq1q2rokWL6qGHHtKgQYPUtGlTSdL48eNVrlw5BQQEKDIyUi+//LISEhIkSWvXrlVQUJAkqV69erLZbFq7dq0kaePGjapVq5b8/f0VGRmpHj16KDEx0ZTzBGA9Pj4+erBSZa1ZvcqxLiMjQ2vWrNJDD1c3sTJ4Or9cdoUH+eq3a2n6fM9Z9f58v/os/v9FkmZvOaXJ67gRCv98lmpMAwMDFRgYqCVLliglJeWm29jtdk2aNEn79+/X3LlztXr1avXv31+SVKNGDcXG3vjX4qJFi3T27FnVqFFDR44cUePGjfXkk09q7969WrhwoTZu3Khu3brd9BgpKSmKj493WnD7EhIStGfPbu3Zs1uSdPz4Me3Zs1unTp40tzDgf3r06qPZ772rD+fN1cEDB9SjaxclJSaqbUx7s0uDB4l5qLAeCA9UgUAflSoYoAENo5RhGNpw5JIuX7uuk78lOy2SdCEhVecTUk2uHDnO5ubFgmyGYVhqGrRFixbpxRdf1LVr11SpUiXVrl1brVu3Vvny5W+6/WeffabOnTvr4sWLkm6krnny5NGaNWtUp04dSVLHjh3l5eWld955x/G5jRs3qnbt2kpMTJSfn5/TPocPH64RI0ZkOdbZC5cVHBycQ2fqedavW6vHGtXLsr7Nv2M0c9ZsEyq6e9jtFv0N8w80feoUTRj/ps7Fxal8hYoaN2GSHqpWzeyy/tGenbPd7BL+UfrULaEHwgMV5JdLV5Kv60Bcgj7aflpxV28e2CzuWEVjVh7W1hOX72yhd4G0awla1qOurly5Yqm/3+Pj4xUSEqKtsWcUGOSeuhKuxuuhUhGWO3fLNaaSlJycrA0bNuiHH37Q8uXLtXXrVs2aNUvt2rXTd999pzFjxujgwYOKj4/X9evXlZycrMTEROXOnfumjWnVqlW1d+9eeXt7O45hGIaSkpL0008/qXTp0k7HT0lJcUps4+PjFRkZSWMKy6IxhZXRmMKqrN6Ybos969bGtGqpQpY7d0tdys/k5+enhg0basiQIdq0aZPatWunYcOG6fjx42rSpInKly+vRYsWaceOHZo6daqkG3MQ3kpCQoI6deqk3bt3O5Y9e/bo0KFDKlmyZJbtfX19FRwc7LQAAADAvSx3V/7NlClTRkuWLNGOHTuUkZGhcePGyW6/0VN/8sknf/n5SpUq6aefflJUVJS7SwUAAMgR7pzWyarTRVkqMf31119Vr149ffjhh9q7d6+OHTumTz/9VGPHjlWzZs0UFRWltLQ0TZ48WUePHtUHH3ygGTNm/OV+BwwYoE2bNqlbt27avXu3Dh06pC+++OKWNz8BAADgzrNUYhoYGKhq1appwoQJOnLkiNLS0hQZGakXX3xR//nPf+Tv76/x48frjTfe0KBBg/Too49qzJgxatu27Z/ut3z58lq3bp0GDx6sWrVqyTAMlSxZUs8888wdOjMAAADXeOI8ppa8+clqMgchc/MTrIqbn2Bl3PwEq7L6zU87fnbvzU+V77PezU+WSkwBAADwPx4YmVpqjCkAAAA8F4kpAACABdn+98dd+7YiElMAAABYAokpAACAFblxHlOLBqYkpgAAALAGElMAAAAL8sCb8klMAQAAYA0kpgAAAFbkgZEpiSkAAAAsgcQUAADAgpjHFAAAADAJiSkAAIAF2dw4j6nb5ke9TSSmAAAAsAQSUwAAAAvywJvySUwBAABgDSSmAAAAVuSBkSmJKQAAACyBxBQAAMCCmMcUAAAAMAmJKQAAgAXZ5MZ5TN2z29tGYgoAAABLIDEFAACwIA+8KZ/EFAAAANZAYgoAAGBBNpsbx5haNDIlMQUAAIAlkJgCAABYkueNMiUxBQAAgCWQmAIAAFgQY0wBAAAAk5CYAgAAWJDnjTAlMQUAAIBFkJgCAABYEGNMAQAAAJOQmAIAAFiQ7X9/3LVvKyIxBQAAgCWQmAIAAFiRB96WT2IKAAAASyAxBQAAsCAPDExJTAEAAGANJKYAAAAWxDymAAAAgElITAEAACyIeUwBAAAAk5CYAgAAWJEH3pZPYgoAAABLIDEFAACwIA8MTElMAQAAYA0kpgAAABbkifOY0pgCAABYkvumi7LqxXwu5QMAAMASSEwBAAAsyBMv5ZOYAgAAwBJoTAEAAGAJNKYAAACwBMaYAgAAWBBjTAEAAACTkJgCAABYkM2N85i6b37U20NiCgAAAEsgMQUAALAgxpgCAAAAJiExBQAAsCCb3PdEe4sGpiSmAAAAsAYSUwAAACvywMiUxBQAAACWQGIKAABgQcxjCgAAAJiExBQAAMCCmMcUAAAAMAmJKQAAgAV54E35JKYAAACwBhJTAAAAK/LAyJTEFAAAAJZAYwoAAGBBNjf/cdXUqVNVrFgx+fn5qVq1atq6dWuOnzONKQAAAP7UwoUL1adPHw0bNkw7d+5UhQoVFB0drfPnz+focWhMAQAALChzHlN3La4YP368XnzxRbVv315lypTRjBkzlDt3br3//vs5es7c/JQNhmFIkq5ejTe5EuDm7HaLjmIHJKVdSzC7BOCm0q4lSvr/v+etJj7efX1H5r7/eAxfX1/5+vo6rUtNTdWOHTs0aNAgxzq73a4GDRpo8+bNOVoXjWk2XL16VZJ0X4kiJlcCAABy2tWrVxUSEmJ2GQ4+Pj4KDw/XvcUj3XqcwMBARUY6H2PYsGEaPny407qLFy8qPT1dYWFhTuvDwsJ08ODBHK2JxjQbIiIidOrUKQUFBclm1Wd4/YPEx8crMjJSp06dUnBwsNnlAE74fsLK+H7mLMMwdPXqVUVERJhdihM/Pz8dO3ZMqampbj2OYRhZ+po/pqV3Go1pNtjtdhUuXNjsMu46wcHB/GKFZfH9hJXx/cw5VkpKf8/Pz09+fn5mlyFJyp8/v7y8vHTu3Dmn9efOnVN4eHiOHoubnwAAAHBLPj4+qly5slatWuVYl5GRoVWrVql69eo5eiwSUwAAAPypPn36KCYmRlWqVNFDDz2kiRMnKjExUe3bt8/R49CY4o7z9fXVsGHDTB/HAtwM309YGd9PmOWZZ57RhQsXNHToUMXFxalixYpasWJFlhuibpfNsOocCQAAAPAojDEFAACAJdCYAgAAwBJoTAEAAGAJNKYAAACwBBpTAAAAWAKNKQAAACyBxhQAgLsAsz/ibkBjCtNl/jL9/S9VfsHCqn7/3czIyDCxEuCGzO+kzWYzuRLg9vHkJ5jKMAzZbDatWLFCH3/8sWw2m5588kk98cQTZpcGOMn8riYmJsrLy0v+/v6y2/m3PcyV+b3csGGDli1bpqSkJEVFRalHjx5mlwb8LfxWhSl+/y/8b775Ri1btlRiYqJOnz6tZs2aaeLEieYWCMg5zbfZbFq2bJmaN2+uRx55RI888oiWL1+u+Ph4k6uEJ7PZbPr888/VtGlTnT59Wj4+Purdu7f+/e9/KykpyezyAJfRmMIUmZecLl68qLNnz+qtt97SZ599pi+++EJvv/22+vbtq7feesvkKuHJMptRSY6mtFWrVqpdu7beffddBQQE6IUXXtDBgwdNrhSeZPr06Vq1apXj9YkTJzRw4ECNGDFCH3zwgfr06aPQ0FCFhoYqd+7cJlYK/D1cyodpYmNjVbp0aRUrVkyjRo2SJOXOnVvdu3eXJPXq1UteXl7q3bu3mWXCA73yyitKSUnRlClTlJ6erpSUFE2bNk39+vXTkCFD9Ouvv+rIkSNq0aKFHnroIbPLhYcYMmSIpkyZor179zrWXb16VYGBgerRo4dOnjypGjVq6Omnn9bkyZMlSZs3b1b16tXNKhlwGYkp7qjf3zhSuHBhDRw4UKdPn9bp06ed3u/evbumTJmiV155xfELFrgTpk+frtmzZ6tXr16SJLvdrty5c+vChQtq2bKlfv31V5UrV07169fXtGnTJEmLFi3S+fPnTawad7vLly/rhx9+0NChQxUZGamDBw/q6tWr8vPzU1pamr788kvVrl1bjz/+uKZMmSJJ+vHHH/XGG29oz549JlcPZB+JKe4om82mrVu3Kn/+/CpRooQGDRokSRo0aJCKFCmi1q1bO7bt0qWLvL29VbNmTbPKhQeKi4tTtWrVFBUVpfXr1ysuLk6tWrVSUFCQJk6cqHXr1ql58+aOcdC//fab3n//fcXHx6t9+/bmFo+7lre3ty5duqTNmzcrMDBQnTt31u7duxUREaGiRYvq+eef12OPPaZ33nnH8ZkPPvhAly5dUqFChUysHHANjSnuqNTUVD311FPKly+fFi9erGLFiunVV19Venq62rRpI5vNpmeeecaxfceOHU2sFp7GMAzlyZNHcXFx6ty5s2bOnKnly5dLktq2bashQ4YoPDzckZRK0ltvvaUjR46obt26ZpWNu5xhGAoICNDy5ctVpEgRLV26VG+++abKlSsnSerUqZP27t0rb29vffnll8qXL58+/fRTzZkzR+vXr1fBggVNPgMg+2hMcUf5+Pho06ZNqlevnv79739r3rx5Kl68uIYNGyZJiomJUXJysmJiYkyuFJ5k06ZNqlChggICAtSrVy99+umnmjdvntq0aaPo6GhJUnR0tHbu3KlvvvlGrVu31gMPPKCff/5ZX331ldauXatixYqZexK4a2XehHfp0iWlpqbK29tb+/btU1xcnMLDw/XEE08oISFBc+fO1fPPP68SJUood+7cWrduncqXL29y9YBrbAYzmcONMu9sTk9Pl5eXlzIyMmS323X69Gk98sgjKly4sKM5TUpKUv/+/fXxxx/r+PHjCgoKMrt83OUMw9DXX3+t559/XocPH1ZwcLBSU1MVFBSkqlWrKj09Xe3atVPbtm0VHBys06dP67vvvtOcOXNkt9tVvHhx9enTR2XKlDH7VHAXy/w9euzYMV2+fFne3t56+OGH1bx5c7311lsKDw+XdGMc6m+//SZ/f3/lzp1bwcHBJlcOuI7GFG63du1aTZkyRe+9955CQkIcv2RPnz6tGjVqKCoqSjNnzlTJkiV17do1Xb16lUtPuKPOnj2rQoUK6eTJkypSpIgSExMVEBCgmJgY7d27Vx07dlTbtm2z/GMp8x9agDtk/q5MS0uTt7e303ubNm1So0aN1Lx5c40bN05hYWEmVQnkLH6jIsf98ssvmj9/vt59912dOXNG/v7+WrJkiTp37qz4+HhHgnrPPfdo2rRpWrNmjdq1a6fjx4/L39+fphR3TOYjRQsWLKiff/5ZxYoV09tvv63U1FRJ0ty5c1WhQgXNmjVL8+bNU2JiotPneAQk3CWzKV29erVeeukltWnTxnGzqCTVqFFDK1eu1JIlSzRgwACdO3fOxGqBnENjihy1f/9+NWnSRCtWrNDhw4cVERGhatWqacuWLVq9erXat2+vK1euyMvLS5KUK1cuNWnShKfnwBSZaaeXl5fuu+8+9erVS4MGDdLChQt15coVSdKcOXNUoUIFzZkzRzNmzFBSUpLjczSmcIfMpnTx4sVq0aKFvL29FRkZqQULFqhFixa6fv26JKl69er67rvvNG/ePA0dOtTxDybgn4xL+cgx+/fvV61atdS1a1f169fPMb7pyy+/VEBAgPLnz6/GjRurevXqevPNN1W4cGGNHj1ahmFo6NChypWLe/Fw52T+5f/7JzxJ0sCBAzVu3DhNnjxZzz77rEJCQiRJTz75pC5evKglS5YoT548ZpWNu1DmkJDfDw3Zs2ePWrVqpV69eqlLly46fvy4atSoobi4OD3yyCNatWqV4/L+tm3bFBQUpPvvv9/M0wByBI0pcsSlS5fUokULlS9f3mlC/DfeeEODBg1SnTp1NHjwYEVERCg6OlppaWnKnz+/zpw5o9WrV6tChQomVg9Pk9mMrlu3TkuXLlWBAgVUr149ValSRdKtm9MzZ84oIiLCzNJxl8lsRo8fP65vv/1WDz74oKpWrarly5dr5cqVGj9+vE6dOqU6deqofv36at26tZo1a6aGDRtqwYIF8vHxMfsUgJxlADngp59+MkqWLGmsXr3aSE9PNwzDMKZPn254e3sbU6ZMMRo2bGg0btzY+P77742rV68aU6dONaZMmWL8/PPPJlcOT5P5/fz666+NXLlyGU2aNDFCQ0ON+vXrG++8845juwEDBhj+/v7GhAkTjCtXrphVLu5imd/FvXv3Gvfdd5/RokULY+nSpY73d+/ebWRkZBjNmzc32rRpY2RkZBgJCQlGlSpVDJvNZkRHR5tVOuA2JKbIER9++KHatWuntLQ0x2XRX375RceOHVOtWrX0448/qlevXrp06ZIWLVqk4sWLm1wxPEVmIpX5TPHMGSHeeOMNPfDAA+rUqZOOHTumQYMG6ezZs3r22WfVuXNnSTcejbtgwQIdOnRIoaGh5p4I7koHDx5UjRo11KlTJ3Xv3j1LIn/lyhXVrl1bw4cPV/PmzZWSkqJu3bqpRYsWKl26NL9Lcdfh5ifkiGLFiilXrlxavHixpBuXSgsXLqxatWopIyNDZcuW1TPPPKNcuXLJz8/P5GrhSex2uw4ePOh4zv327dvVrVs3bdmyRZUrV5YkFS9eXGPGjFFERIQ++ugjzZw5U5I0efJk7d+/n6YUbpGcnKyhQ4fqueeec3z/JCktLU2nT5/WoUOH5O3trVy5cmnu3Lk6fvy4Xn31Va1fv16VKlWiKcVdicYUOaJYsWIKCQnR3LlzdeLECaebSTIH88fGxqpYsWIKDAw0q0x4qB9++EFJSUnKnz+/bDabzp49q3379mn79u2ObTKb06JFi2rKlCl6//33JUkFChQwq2zc5XLlyqW4uDinm5a++eYb9e/fX2XKlFHDhg3VokULDR48WPv27dMjjzyihQsXasGCBY5J9YG7DY0pckThwoU1bdo0rVixQkOGDNFPP/3keC8+Pl79+/fX+++/r2HDhvFEJ9xxZ8+eVWpqqtLT01W5cmXNmTNH1atX18KFC/Xll186titWrJiGDx+uatWqqX79+pKYEgruk5SUpAsXLmjv3r2KjY3VmDFj1LNnT506dUqjRo3S0KFDderUKa1fv16bNm3SwoULtXXrVj344INmlw64DWNMkWPS09M1a9YsdevWTVFRUapRo4a8vb11+vRpbd++XV9//TW/UOF2mWNKk5OTHcNGRo0apfXr12vlypWOx+Pu2bNHffr0kY+Pj7p06aKmTZs69nH9+nWmL8MdsXr1akVHR+uee+7RpUuX9Oabb6p+/fqKiopSamqqmjRpokKFCmnu3LlmlwrcESSmyDFeXl7q1KmTNm7cqDJlymjHjh3av3+/ypYtqw0bNtCU4o6w2+06ffq02rZtq5UrV0q68Y+mfPnyObbJyMhQhQoV9Oabbyo1NVXvvPOOPvnkE8f7NKW4U+rVq6ejR49q0aJFOnr0qDp16qSoqChJN76HISEhKlKkiAzDEDkSPAGJKdwiM5UCzHD06FE9//zzCg0N1WuvvabPPvtMv/zyi+bNm5dl23PnzqlBgwaqWLGipk+fzhhoWEJqaqpGjRql999/X2vXrtW9995rdknAHUFjCrcwfvc0HeMPT9YB7oTDhw+rW7duCggI0IkTJ2QYhsqWLSu73S673a6UlBTZbDaFhITop59+0qxZs1SiRAmzywb04Ycfatu2bVq4cKGWL1/O1SZ4FC7lwy1+34jSlMIMUVFRevvtt3Xt2jXFxsbqxIkTyp07t86cOaPTp08rOTlZ8fHxOnLkiKZOnUpTCkuIjY3Ve++9p1OnTmnNmjU0pfA4JKYA7mqHDx9Wr169lJqaqnHjxqlcuXJmlwT8qfPnz8vX19fxKFzAk9CYArjr/fzzz+rRo4ckafDgwapVq5bjPYaaAIB1cCkfwF3vvvvu0+TJk+Xt7a3+/ftry5YtjvdoSgHAOmhMAXiEe++9V2+++aYKFy6sQoUKmV0OAOAmuJQPwKOkpqbKx8fH7DIAADdBYwoAAABL4FI+AAAALIHGFAAAAJZAYwoAAABLoDEFAACAJdCYAgAAwBJoTAEAAGAJNKYA/nHatWun5s2bO17XqVNHvXr1uuN1rF27VjabTZcvX77lNjabTUuWLMn2PocPH66KFSveVl3Hjx+XzWbT7t27b2s/AHCn0ZgCyBHt2rWTzWaTzWaTj4+PoqKiNHLkSF2/ft3tx/788881atSobG2bnWYSAGCOXGYXAODu0bhxY82ePVspKSn6+uuv1bVrV3l7e2vQoEFZts3JJzDlzZs3R/YDADAXiSmAHOPr66vw8HAVLVpUXbp0UYMGDfTll19K+v/L76+//roiIiJUqlQpSdKpU6fUqlUrhYaGKm/evGrWrJmOHz/u2Gd6err69Omj0NBQ5cuXT/3799cfH1j3x0v5KSkpGjBggCIjI+Xr66uoqCi99957On78uOrWrStJypMnj2w2m9q1aydJysjI0JgxY1S8eHH5+/urQoUK+uyzz5yO8/XXX+u+++6Tv7+/6tat61Rndg0YMED33XefcufOrRIlSmjIkCFKS0vLst0777yjyMhI5c6dW61atdKVK1ec3p81a5ZKly4tPz8/3X///Zo2bZrLtQCA1dCYAnAbf39/paamOl6vWrVKsbGxWrlypZYuXaq0tDRFR0crKChIGzZs0Pfff6/AwEA1btzY8blx48Zpzpw5ev/997Vx40ZdunRJixcv/tPjtm3bVh9//LEmTZqkAwcO6J133lFgYKAiIyO1aNEiSVJsbKzOnj2rt99+W5I0ZswYzZs3TzNmzND+/fvVu3dvPf/881q3bp2kGw10y5Yt9cQTT2j37t3q2LGjBg4c6PLPJCgoSHPmzNFPP/2kt99+W++++64mTJjgtM3hw4f1ySef6KuvvtKKFSu0a9cuvfzyy47358+fr6FDh+r111/XgQMHNHr0aA0ZMkRz5851uR4AsBQDAHJATEyM0axZM8MwDCMjI8NYuXKl4evra/Tt29fxflhYmJGSkuL4zAcffGCUKlXKyMjIcKxLSUkx/P39jW+++cYwDMMoVKiQMXbsWMf7aWlpRuHChR3HMgzDqF27ttGzZ0/DMAwjNjbWkGSsXLnypnWuWbPGkGT89ttvjnXJyclG7ty5jU2bNjlt26FDB+PZZ581DMMwBg0aZJQpU8bp/QEDBmTZ1x9JMhYvXnzL9998802jcuXKjtfDhg0zvLy8jF9++cWxbvny5YbdbjfOnj1rGIZhlCxZ0vjoo4+c9jNq1CijevXqhmEYxrFjxwxJxq5du255XACwIsaYAsgxS5cuVWBgoNLS0pSRkaHnnntOw4cPd7xfrlw5p3Gle/bs0eHDhxUUFOS0n+TkZB05ckRXrlzR2bNnVa1aNcd7uXLlUpUqVbJczs+0e/dueXl5qXbt2tmu+/Dhw0pKSlLDhg2d1qempurBBx+UJB04cMCpDkmqXr16to+RaeHChZo0aZKOHDmihIQEXb9+XcHBwU7bFClSRPfcc4/TcTIyMhQbG6ugoCAdOXJEHTp00IsvvujY5vr16woJCXG5HgCwEhpTADmmbt26mj59unx8fBQREaFcuZx/xQQEBDi9TkhIUOXKlTV//vws+ypQoMDfqsHf39/lzyQkJEiSli1b5tQQSjfGzeaUzZs3q02bNhoxYoSio6MVEhKiBQsWaNy4cS7X+u6772ZplL28vHKsVgAwA40pgBwTEBCgqKiobG9fqVIlLVy4UAULFsySGmYqVKiQtmzZokcffVTSjWRwx44dqlSp0k23L1eunDIyMrRu3To1aNAgy/uZiW16erpjXZkyZeTr66uTJ0/eMmktXbq040auTD/88MNfn+TvbNq0SUWLFtXgwYMd606cOJFlu5MnT+rMmTOKiIhwHMdut6tUqVIKCwtTRESEjh49qjZt2rh0fACwOm5+AmCaNm3aKH/+/GrWrJk2bNigY8eOae3aterRo4d++eUXSVLPnj313//+V0uWLNHBgwf18ssv/+kcpMWKFVNMTIxeeOEFLVmyxLHPTz75RJJUtGhR2Ww2LV26VBcuXFBCQoKCgoLUt29f9e7dW3PnztWRI0e0c+dOTZ482XFDUefOnXXo0CH169dPsbGx+uijjzRnzhyXzvfee+/VyZMntWDBAh05ckSTJk266Y1cfn5+iomJ0Z49e7Rhwwb16NFDrVq1Unh4uCRpxIgRGjNmjCZNmqSff/5Z+/bt0+zZszV+/HiX6gEAq6ExBWCa3Llza/369SpSpIhatmyp0qVLq0OHDkpOTnYkqK+88or+/e9/KyYmRtWrV1dQUJBatGjxp/udPn26nnrqKb388su6//779eKLLyoxMVGSdM8992jEiBEaOHCgwsLC1K1bN0nSqFGjNGTIEI0ZM0alS5dW48aNtWzZMhUvXlzSjXGfixYt0pIlS1ShQgXNmDFDo0ePdul8mzZtqt69e6tbt26qWLGiNm3apCFDhmTZLioqSi1bttS//vUvNWrUSOXLl3eaDqpjx46aNWuWZs+erXLlyql27dqaM2eOo1YA+KeyGbe6gwAAAAC4g0hMAQAAYAk0pgAAALAEGlMAAABYAo0pAAAALIHGFAAAAJZAYwoAAABLoDEFAACAJdCYAgAAwBJoTAEAAGAJNKYAAACwBBpTAAAAWML/ARzqywWx1M0uAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraies"
      ],
      "metadata": {
        "id": "zC_ydc7OHLzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, concatenate, Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "1WLL4GbYHQfA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading dataset"
      ],
      "metadata": {
        "id": "sXteijwVHidy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0Uj2cgSIJZD",
        "outputId": "39789a03-27e4-4de4-d6ce-04aecd866761"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "def load_image(img_path, img_size):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, img_size, mode='constant', preserve_range=True)\n",
        "    return img\n",
        "\n",
        "def load_mask(mask_path, mask_size):\n",
        "    mask = imread(mask_path, as_gray=True)\n",
        "    mask = resize(mask, mask_size, mode='constant', preserve_range=True)\n",
        "    mask = np.expand_dims(mask, axis=-1)  # Add channel dimension\n",
        "    return mask\n",
        "\n",
        "def load_dataset(image_folder_gun, image_folder_knife, image_folder_safe=None, mask_folder_gun=None, mask_folder_knife=None, img_size=(128, 128, 3), mask_size=(128, 128, 1)):\n",
        "    X_gun, y_gun = load_data_category(image_folder_gun, mask_folder_gun, img_size, mask_size)\n",
        "    X_knife, y_knife = load_data_category(image_folder_knife, mask_folder_knife, img_size, mask_size)\n",
        "\n",
        "    X_safe = None\n",
        "    y_safe = None\n",
        "    if image_folder_safe:\n",
        "        X_safe, y_safe = load_data_category(image_folder_safe, None, img_size, mask_size)\n",
        "\n",
        "    # Combine the data from all categories\n",
        "    X = np.concatenate((X_gun, X_knife), axis=0)\n",
        "    y = np.concatenate((y_gun, y_knife), axis=0)\n",
        "    if X_safe is not None:\n",
        "        X = np.concatenate((X, X_safe), axis=0)\n",
        "        y = np.concatenate((y, y_safe), axis=0)\n",
        "\n",
        "    print(f\"Loaded images shape: {X.shape}\")\n",
        "    print(f\"Loaded masks shape: {y.shape}\")\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def load_data_category(image_folder, mask_folder, img_size, mask_size):\n",
        "    image_paths = sorted([os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpg') or f.endswith('.png')])\n",
        "\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = load_image(img_path, img_size)\n",
        "        X.append(img)\n",
        "\n",
        "        if mask_folder:\n",
        "            # Find corresponding mask path (if exists)\n",
        "            mask_name = os.path.splitext(os.path.basename(img_path))[0] + '.png'\n",
        "            mask_path = os.path.join(mask_folder, mask_name)\n",
        "            if os.path.exists(mask_path):\n",
        "                mask = load_mask(mask_path, mask_size)\n",
        "            else:\n",
        "                mask = np.zeros(mask_size)\n",
        "                mask = np.expand_dims(mask, axis=-1)\n",
        "        else:\n",
        "            # No masks provided, use a dummy mask\n",
        "            mask = np.zeros(mask_size)\n",
        "            mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "        y.append(mask)\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Normalize the images and masks\n",
        "    X = X / 255.0\n",
        "    y = y / 255.0\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Example paths\n",
        "train_image_folder_gun = '/content/drive/MyDrive/students_data/train/gun'\n",
        "train_mask_folder_gun = '/content/drive/MyDrive/students_data/train/annotations/gun'\n",
        "train_image_folder_knife = '/content/drive/MyDrive/students_data/train/knife'\n",
        "train_mask_folder_knife = '/content/drive/MyDrive/students_data/train/annotations/knife'\n",
        "train_image_folder_safe = '/content/drive/MyDrive/students_data/train/safe'\n",
        "\n",
        "X, y = load_dataset(train_image_folder_gun, train_image_folder_knife, train_image_folder_safe, train_mask_folder_gun, train_mask_folder_knife)\n",
        "\n",
        "print(f\"Final loaded images shape: {X.shape}\")\n",
        "print(f\"Final loaded masks shape: {y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu_iYH0HHaG7",
        "outputId": "262f51e2-a190-4cdb-a906-18c2a388f0d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded images shape: (1542, 128, 128, 3)\n",
            "Loaded masks shape: (1542, 128, 128, 1, 1)\n",
            "Final loaded images shape: (1542, 128, 128, 3)\n",
            "Final loaded masks shape: (1542, 128, 128, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Model"
      ],
      "metadata": {
        "id": "V-9p3tcQL_oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Input, concatenate, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    c1 = BatchNormalization()(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    c2 = BatchNormalization()(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    c3 = BatchNormalization()(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    c4 = BatchNormalization()(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "    c5 = BatchNormalization()(c5)\n",
        "\n",
        "    # Decoder\n",
        "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "    c6 = BatchNormalization()(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "    c7 = BatchNormalization()(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "    c8 = BatchNormalization()(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "    c9 = BatchNormalization()(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = unet_model(input_size=(128, 128, 3))\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShC8-7PeMCfg",
        "outputId": "d180d3f5-f666-4a5f-f9b7-566dd7c66495"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 128, 128, 64)         1792      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 128, 128, 64)         256       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 128, 128, 64)         36928     ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 128, 128, 64)         256       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 64, 64, 64)           0         ['batch_normalization_19[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 64, 64, 128)          73856     ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 64, 64, 128)          512       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 64, 64, 128)          147584    ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 64, 64, 128)          512       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 32, 32, 128)          0         ['batch_normalization_21[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 32, 32, 256)          295168    ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 32, 32, 256)          1024      ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 32, 32, 256)          590080    ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 32, 32, 256)          1024      ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 16, 16, 256)          0         ['batch_normalization_23[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 16, 16, 512)          1180160   ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 16, 16, 512)          2048      ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 16, 16, 512)          2359808   ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 16, 16, 512)          2048      ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 8, 8, 512)            0         ['batch_normalization_25[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 8, 8, 1024)           4719616   ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 8, 8, 1024)           4096      ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 8, 8, 1024)           9438208   ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 8, 8, 1024)           4096      ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2D  (None, 16, 16, 512)          2097664   ['batch_normalization_27[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 16, 16, 1024)         0         ['conv2d_transpose_4[0][0]',  \n",
            " )                                                                   'batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 16, 16, 512)          4719104   ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 16, 16, 512)          2048      ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 16, 16, 512)          2359808   ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 16, 16, 512)          2048      ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_5 (Conv2D  (None, 32, 32, 256)          524544    ['batch_normalization_29[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 32, 32, 512)          0         ['conv2d_transpose_5[0][0]',  \n",
            " )                                                                   'batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 32, 32, 256)          1179904   ['concatenate_5[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 32, 32, 256)          1024      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 32, 32, 256)          590080    ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 32, 32, 256)          1024      ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_6 (Conv2D  (None, 64, 64, 128)          131200    ['batch_normalization_31[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 64, 64, 256)          0         ['conv2d_transpose_6[0][0]',  \n",
            " )                                                                   'batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 64, 64, 128)          295040    ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 64, 64, 128)          512       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 64, 64, 128)          147584    ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 64, 64, 128)          512       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_7 (Conv2D  (None, 128, 128, 64)         32832     ['batch_normalization_33[0][0]\n",
            " Transpose)                                                         ']                            \n",
            "                                                                                                  \n",
            " concatenate_7 (Concatenate  (None, 128, 128, 128)        0         ['conv2d_transpose_7[0][0]',  \n",
            " )                                                                   'batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 128, 128, 64)         73792     ['concatenate_7[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 128, 128, 64)         256       ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 128, 128, 64)         36928     ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 128, 128, 64)         256       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 128, 128, 1)          65        ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31055297 (118.47 MB)\n",
            "Trainable params: 31043521 (118.42 MB)\n",
            "Non-trainable params: 11776 (46.00 KB)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train n Save"
      ],
      "metadata": {
        "id": "2gqSPqiOH2tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, y, batch_size=8, epochs=5, verbose=1, validation_split=0.1)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/students_data/unet_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR3bPVsSH34y",
        "outputId": "e773799b-79d9-4585-a713-199f5eae030f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 15/174 [=>............................] - ETA: 42:28 - loss: 0.7077 - accuracy: 0.5799"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predicting on test image\n"
      ],
      "metadata": {
        "id": "n_pQys2PH-fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_test_image(img_path, img_size=(128, 128, 3)):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, img_size, mode='constant', preserve_range=True)\n",
        "    img = img / 255.0  # Normalize the image\n",
        "    return img\n",
        "\n",
        "# Load a test image\n",
        "test_image_path = 'path_to_test_image.jpg'\n",
        "test_image = load_test_image(test_image_path)\n",
        "test_image = np.expand_dims(test_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Predict the segmentation mask\n",
        "predicted_mask = model.predict(test_image)\n",
        "predicted_mask = (predicted_mask > 0.5).astype(np.uint8)  # Threshold to binary mask\n",
        "\n",
        "# Display the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('Test Image')\n",
        "plt.imshow(imread(test_image_path))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('Predicted Mask')\n",
        "plt.imshow(predicted_mask[0, :, :, 0], cmap='gray')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0S1e7vyrH5fm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}